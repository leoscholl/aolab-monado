// Copyright 2021-2022, Collabora Ltd.
// Author: Jakob Bornecrantz <jakob@collabora.com>
// SPDX-License-Identifier: BSL-1.0

#version 460
#extension GL_GOOGLE_include_directive : require

#include "srgb.inc.glsl"


// The size of the distortion texture dimensions in texels.
layout(constant_id = 0) const int distortion_texel_count = 2;

// Should we do timewarp.
layout(constant_id = 1) const bool do_timewarp = false;

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

layout(set = 0, binding = 0) uniform sampler2D source[2];
layout(set = 0, binding = 1) uniform sampler2D distortion[6];
layout(set = 0, binding = 2) uniform writeonly restrict image2D target;
layout(set = 0, binding = 3, std140) uniform restrict Config
{
	ivec4 views[2];
	vec4 pre_transform[2];
	vec4 post_transform[2];
	mat4 transform[2];
	vec2 src_sizes[2];
} ubo;


vec2 position_to_uv(ivec2 extent, vec2 xy)
{
	// The inverse of the extent of the target image is the pixel size in [0 .. 1] space.
	vec2 extent_pixel_size = vec2(1.0 / float(extent.x), 1.0 / float(extent.y));

	// Per-target pixel we move the size of the pixels.
	vec2 dist_uv = xy * extent_pixel_size;

	// Emulate a triangle sample position by offset half target pixel size.
	dist_uv = dist_uv + extent_pixel_size / 2.0;


	// To correctly sample we need to put position (0, 0) in the
	// middle of the (0, 0) texel in the distortion textures. That's why we
	// offset with half the texel size, pushing all samples into the middle
	// of each texels, a kin to a vertex buffer. We need to put uv coord
	// (1, 1) in the middle of the last texel, that pixel is (size - 1)
	// texels away from the first texel. So we need to scale [0 .. 1] to
	// [0 .. size - 1].

#define DIM (float(distortion_texel_count))
#define STRETCH ((DIM - 1.0) / DIM)
#define OFFSET (1.0 / (DIM * 2.0))

	dist_uv = (dist_uv * STRETCH) + OFFSET;

	return dist_uv;
}

vec2 transform_uv_subimage(vec2 uv, uint iz)
{
	vec2 values = uv;

	// To deal with OpenGL flip and sub image view.
	values.xy = values.xy * ubo.post_transform[iz].zw + ubo.post_transform[iz].xy;

	// Ready to be used.
	return values.xy;
}

vec2 transform_uv_timewarp(vec2 uv, uint iz)
{
	vec4 values = vec4(uv, -1, 1);

	// From uv to tan angle (tangent space).
	values.xy = values.xy * ubo.pre_transform[iz].zw + ubo.pre_transform[iz].xy;
	values.y = -values.y; // Flip to OpenXR coordinate system.

	// Timewarp.
	values = ubo.transform[iz] * values;
	values.xy = values.xy * (1.0 / max(values.w, 0.00001));

	// From [-1, 1] to [0, 1]
	values.xy = values.xy * 0.5 + 0.5;

	// To deal with OpenGL flip and sub image view.
	values.xy = values.xy * ubo.post_transform[iz].zw + ubo.post_transform[iz].xy;

	// Done.
	return values.xy;
}

vec2 transform_uv(vec2 uv, uint iz)
{
	if (do_timewarp) {
		return transform_uv_timewarp(uv, iz);
	} else {
		return transform_uv_subimage(uv, iz);
	}
}

vec2 distorted_uv(ivec2 extent, vec2 xy, uint iz)
{
	vec2 dist_uv = position_to_uv(extent, xy);

	// Only read red channel, we don't do color aberration
	vec2 r_uv = texture(distortion[iz + 0], dist_uv).xy;

	// Do any transformation needed.
	return transform_uv(r_uv, iz);
}

void main()
{
	uint ix = gl_GlobalInvocationID.x;
	uint iy = gl_GlobalInvocationID.y;
	uint iz = gl_GlobalInvocationID.z;

	ivec2 offset = ivec2(ubo.views[iz].xy);
	ivec2 extent = ivec2(ubo.views[iz].zw);
	ivec2 src_extent = ivec2(ubo.src_sizes[iz]);

	if (ix >= extent.x || iy >= extent.y) {
		return;
	}

	// extent of the area to sample in normalized coordinates
	vec2 u0 = distorted_uv(extent, max(vec2(0, 0), vec2(ix - 0.5, iy - 0.5)), iz);
	vec2 u1 = distorted_uv(extent, min(extent, vec2(ix + 0.5, iy + 0.5)), iz);

	if (u0.y > u1.y)
	{
		float tmp = u0.y;
		u0.y = u1.y;
		u1.y = tmp;
	}

	// extent in pixel coordinates
	vec2 p0 = u0 * (src_extent - 1);
	vec2 p1 = u1 * (src_extent - 1);

	// shrink by 1/2 pixel to prevent overlap
	p0 += vec2(0.5);
	p1 -= vec2(0.5);

	// iteration area
	vec2 i0, i1;
	// If there is less than one pixel, just sample it
	if (p1.x - p0.x <= 1)
		i0.x = i1.x = distorted_uv(extent, vec2(ix, iy), iz).x * src_extent.x;
	else
	{
		i0.x = floor(p0.x);
		i1.x = ceil(p1.x);
	}
	if (p1.y - p0.y <= 1)
		i0.y = i1.y = distorted_uv(extent, vec2(ix, iy), iz).y * src_extent.y;
	else
	{
		i0.y = floor(p0.y);
		i1.y = ceil(p1.y);
	}

	vec4 colour = vec4(0, 0, 0, 1);

	float count = 0;
	for (float y = i0.y ; y <= i1.y ; y++) {
		float wy = 1;
		if (y < p0.y)
			wy *= 1 - (p0.y - y);
		if (y > p1.y)
			wy *= 1 - (y - p1.y);
		for (float x = i0.x; x <= i1.x; x++) {
			float w = wy;
			if (x < p0.x)
				w *= 1 - (p0.x - x);
			if (x > p1.x)
				w *= 1 - (x - p1.x);
			vec2 uv = (vec2(x, y) + 0.5) / src_extent;
			colour.rgb += w * texture(source[iz], uv).rgb;
			count += w;
		}
	}

	colour /= count;
	// Do colour correction here since there are no automatic conversion in hardware available.
	colour = vec4(from_linear_to_srgb(colour.rgb), 1);

	imageStore(target, ivec2(offset.x + ix, offset.y + iy), colour);
}
